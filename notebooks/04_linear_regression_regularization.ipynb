{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dda0f6e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================\n",
    "# 1. Imports\n",
    "# ================================================\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3a813683",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================\n",
    "# 2. Load datasets (train + eval)\n",
    "# ================================================\n",
    "train_df = pd.read_csv(\"C:\\\\Users\\\\HP\\\\Documents\\\\repos\\\\mlops-regression-mlflow\\\\data\\\\processed\\\\feature_engineered_train.csv\")\n",
    "eval_df  = pd.read_csv(\"C:\\\\Users\\\\HP\\\\Documents\\\\repos\\\\mlops-regression-mlflow\\\\data\\\\processed\\\\feature_engineered_eval.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4f794af9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# ================================================\\n# 3. Drop high VIF features (both train + eval)\\n# ================================================\\nhigh_vif_features = [\\n    \"median_sale_price\" #highest correlation to \\'price\\' => data leakage\\n]\\ntrain_df.drop(columns=high_vif_features, inplace=True)\\neval_df.drop(columns=high_vif_features, inplace=True)\\n'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# ================================================\n",
    "# 3. Drop high VIF features (both train + eval)\n",
    "# ================================================\n",
    "high_vif_features = [\n",
    "    \"median_sale_price\" #highest correlation to 'price' => data leakage\n",
    "]\n",
    "train_df.drop(columns=high_vif_features, inplace=True)\n",
    "eval_df.drop(columns=high_vif_features, inplace=True)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b13b87a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================\n",
    "# 4. Define target & features\n",
    "# ================================================\n",
    "target = \"price\"\n",
    "X_train = train_df.drop(columns=[target])\n",
    "y_train = train_df[target]\n",
    "\n",
    "X_eval = eval_df.drop(columns=[target])\n",
    "y_eval = eval_df[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ae2eb81e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(y_train.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b2a3c225",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "year                            0\n",
      "quarter                         0\n",
      "month                           0\n",
      "median_list_price               0\n",
      "median_ppsf                     0\n",
      "median_list_ppsf                0\n",
      "homes_sold                      0\n",
      "pending_sales                   0\n",
      "new_listings                    0\n",
      "inventory                       0\n",
      "median_dom                      0\n",
      "avg_sale_to_list                0\n",
      "sold_above_list                 0\n",
      "off_market_in_two_weeks         0\n",
      "bank                            0\n",
      "bus                             0\n",
      "hospital                        0\n",
      "mall                            0\n",
      "park                            0\n",
      "restaurant                      0\n",
      "school                          0\n",
      "station                         0\n",
      "supermarket                     0\n",
      "Total Population                0\n",
      "Median Age                      0\n",
      "Per Capita Income               0\n",
      "Total Families Below Poverty    0\n",
      "Total Housing Units             0\n",
      "Median Rent                     0\n",
      "Median Home Value               0\n",
      "Total Labor Force               0\n",
      "Unemployed Population           0\n",
      "Total School Age Population     0\n",
      "Total School Enrollment         0\n",
      "Median Commute Time             0\n",
      "lat                             0\n",
      "lng                             0\n",
      "zipcode_freq                    0\n",
      "city_encoded                    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(X_train.isna().sum())  # Total number of NaNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0e0d45d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================\n",
    "# 5. Standardization (fit on train, transform eval)\n",
    "# ================================================\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_eval_scaled  = scaler.transform(X_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c28de823",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression:\n",
      " MAE: 54499.23383501457\n",
      " RMSE: 121228.13024065612\n",
      " R²: 0.8864291581715258\n"
     ]
    }
   ],
   "source": [
    "# ================================================\n",
    "# 6. Train & Evaluate Models\n",
    "# ================================================\n",
    "\n",
    "# --- Linear Regression ---\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train_scaled, y_train)\n",
    "y_pred_lr = lr.predict(X_eval_scaled)\n",
    "\n",
    "print(\"Linear Regression:\")\n",
    "print(\" MAE:\", mean_absolute_error(y_eval, y_pred_lr))\n",
    "print(\" RMSE:\", np.sqrt(mean_squared_error(y_eval, y_pred_lr)))\n",
    "print(\" R²:\", r2_score(y_eval, y_pred_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4a88aa0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ridge Regression:\n",
      " MAE: 54499.94263821794\n",
      " RMSE: 121230.21534831254\n",
      " R²: 0.8864252513312916\n"
     ]
    }
   ],
   "source": [
    "# --- Ridge Regression ---\n",
    "ridge = Ridge(alpha=1.0)\n",
    "ridge.fit(X_train_scaled, y_train)\n",
    "y_pred_ridge = ridge.predict(X_eval_scaled)\n",
    "\n",
    "print(\"\\nRidge Regression:\")\n",
    "print(\" MAE:\", mean_absolute_error(y_eval, y_pred_ridge))\n",
    "print(\" RMSE:\", np.sqrt(mean_squared_error(y_eval, y_pred_ridge)))\n",
    "print(\" R²:\", r2_score(y_eval, y_pred_ridge))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "619e8dfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Lasso Regression:\n",
      " MAE: 54820.20724085572\n",
      " RMSE: 121486.86857165465\n",
      " R²: 0.8859438502073558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HP\\Documents\\repos\\mlops-regression-mlflow\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.088e+15, tolerance: 5.209e+12\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    }
   ],
   "source": [
    "# --- Lasso Regression ---\n",
    "lasso = Lasso(alpha=0.1)\n",
    "lasso.fit(X_train_scaled, y_train)\n",
    "y_pred_lasso = lasso.predict(X_eval_scaled)\n",
    "\n",
    "print(\"\\nLasso Regression:\")\n",
    "print(\" MAE:\", mean_absolute_error(y_eval, y_pred_lasso))\n",
    "print(\" RMSE:\", np.sqrt(mean_squared_error(y_eval, y_pred_lasso)))\n",
    "print(\" R²:\", r2_score(y_eval, y_pred_lasso))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "44ca8480",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ElasticNet Regression:\n",
      " MAE: 54789.18642303222\n",
      " RMSE: 122172.22775505307\n",
      " R²: 0.884653341625926\n"
     ]
    }
   ],
   "source": [
    "# --- ElasticNet ---\n",
    "elastic = ElasticNet(alpha=0.1, l1_ratio=0.5)\n",
    "elastic.fit(X_train_scaled, y_train)\n",
    "y_pred_elastic = elastic.predict(X_eval_scaled)\n",
    "\n",
    "print(\"\\nElasticNet Regression:\")\n",
    "print(\" MAE:\", mean_absolute_error(y_eval, y_pred_elastic))\n",
    "print(\" RMSE:\", np.sqrt(mean_squared_error(y_eval, y_pred_elastic)))\n",
    "print(\" R²:\", r2_score(y_eval, y_pred_elastic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c9bc44",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "housing-regression-mle",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
